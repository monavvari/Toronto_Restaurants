{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toronto Restaurants\n",
    "\n",
    "### Scraping Restaurant Data From The Web\n",
    "\n",
    "**Data**  \n",
    "\n",
    "From a market segmentation perspective, we want to collect the most relevant features on as many restaurants as possible within Toronto. Relevant features might include: \n",
    "1. Price\n",
    "2. Average Review\n",
    "3. Reviews Count\n",
    "4. Cuisines\n",
    "5. Location \n",
    "\n",
    "For the most part, this data can be scraped from the web. We'll keep the scope to a single website for the sake of consistency. This will allow us to better handle the platform-idiosyncracies directly affecting reviews or the range of prices. For instance, in most cases, price and review are not continuous numerical values but rather discrete (and even categorical in some cases i.e good - bad or cheap - expensive). Generally, comparing data across platforms isn't apples to apples, so we'll want to find a single platform (website) with an extensive and rich library of Toronto restaurants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries successfully imported!\n"
     ]
    }
   ],
   "source": [
    "# import pandas \n",
    "import pandas as pd # to store our data in a dataframe object\n",
    "\n",
    "# import requests\n",
    "import requests\n",
    "\n",
    "# import selenium (webscraping library)\n",
    "from selenium import webdriver \n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# import BeautifulSoup (handles xml)\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "print('All libraries successfully imported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Assigned driver path and url\n",
    "\n",
    "driver_path = 'YOUR DRIVER PATH' # example: C:\\Program Files (x86)\\Google\\Chrome\\Application\\chromedriver\n",
    "url = 'YOUR URL' # url of website to be scraped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've assigned our driver path and found a website with suitable data, we can begin building our crawler. In my case, \n",
    "the crawler will have to iterate over each restaurant card (a CSS container where the data I want for an individual restaurant is located) and again for every webpage (the restaurant catalogue I will be using spans multiple webpages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " iteration: 5125 Final page reached\n"
     ]
    }
   ],
   "source": [
    "# create webdriver instance\n",
    "\n",
    "driver = webdriver.Chrome(driver_path)\n",
    "\n",
    "# create empty dataframe to host data\n",
    "restaurants = pd.DataFrame(columns = ['occasion', 'name', 'avg review', 'review count', 'neighborhood', 'address', \n",
    "                                     'cuisines', 'cost for 2', 'featured in'])\n",
    "\n",
    "results = driver.get(url) # Feed URL of webpage we are scraping\n",
    "iter_count = 0\n",
    "\n",
    "while True: \n",
    "    # check how many restaurants on page\n",
    "    n_items = driver.find_elements_by_css_selector('.search-result')\n",
    "    \n",
    "    for i, item in enumerate(n_items, 1): \n",
    "        \n",
    "        try: # get data and assign to vars\n",
    "            occasion = driver.find_elements_by_css_selector('#orig-search-list > div:nth-child('+ str(i) +') > div.content > div > article > div.pos-relative.clearfix > div > div.col-s-16.col-m-12.pl0 > div:nth-child(1) > div.col-s-12 > div.res-snippet-small-establishment.mt5 > a')[0]\n",
    "            occasion = occasion.text\n",
    "            name = driver.find_elements_by_css_selector('#orig-search-list > div:nth-child('+ str(i) +') > div.content > div > article > div.pos-relative.clearfix > div > div.col-s-16.col-m-12.pl0 > div:nth-child(1) > div.col-s-12 > a.result-title.hover_feedback.zred.bold.ln24.fontsize0')[0]\n",
    "            name = name.text\n",
    "            avg_review = driver.find_elements_by_css_selector('#orig-search-list > div:nth-child('+ str(i) +') > div.content > div > article > div.pos-relative.clearfix > div > div.col-s-16.col-m-12.pl0 > div:nth-child(1) > div.col-s-12 > div.single-rating.flex > span.rating-value')[0]\n",
    "            avg_review = avg_review.text\n",
    "            review_count = driver.find_elements_by_css_selector('#orig-search-list > div:nth-child('+ str(i) +') > div.content > div > article > div.pos-relative.clearfix > div > div.col-s-16.col-m-12.pl0 > div:nth-child(1) > div.col-s-12 > div.single-rating.flex > span.review-count.medium')[0]\n",
    "            review_count = review_count.text\n",
    "            neighborhood = driver.find_elements_by_css_selector('#orig-search-list > div:nth-child('+ str(i) +') > div.content > div > article > div.pos-relative.clearfix > div > div.col-s-16.col-m-12.pl0 > div:nth-child(1) > div.col-s-12 > a.ln24.search-page-text.mr10.zblack.search_result_subzone.left > b')[0]\n",
    "            neighborhood = neighborhood.text\n",
    "            address = driver.find_elements_by_css_selector('#orig-search-list > div:nth-child('+ str(i) +') > div.content > div > article > div.pos-relative.clearfix > div > div.col-s-16.col-m-12.pl0 > div:nth-child(2) > div')[0]\n",
    "            address = address.text\n",
    "            cuisines = driver.find_elements_by_css_selector('#orig-search-list > div:nth-child('+ str(i) +') > div.content > div > article > div.search-page-text.clearfix.row > div:nth-child(1) > span.col-s-11.col-m-12.nowrap.pl0 > a')\n",
    "            cuisines = [x.text for x in cuisines]\n",
    "            cost_for_2 = driver.find_elements_by_css_selector('#orig-search-list > div:nth-child('+ str(i) +') > div.content > div > article > div.search-page-text.clearfix.row > div.res-cost.clearfix > span.col-s-11.col-m-12.pl0')[0]\n",
    "            cost_for_2 = cost_for_2.text\n",
    "            \n",
    "            try: \n",
    "                featured_in = driver.find_elements_by_css_selector('#orig-search-list > div:nth-child('+ str(i) +') > div.content > div > article > div.search-page-text.clearfix.row > div.res-collections.clearfix > div')\n",
    "                featured_in = [x.text for x in featured_in]\n",
    "            \n",
    "            except: \n",
    "                featured_in = 'NaN'\n",
    "                \n",
    "            iter_count += 1 \n",
    "            print('\\r iteration: {}'.format(iter_count), end = \"\")\n",
    "            \n",
    "            # add obs to df \n",
    "            restaurants.loc[len(restaurants)] = [\n",
    "                occasion, \n",
    "                name,\n",
    "                avg_review,\n",
    "                review_count, \n",
    "                neighborhood,\n",
    "                address,\n",
    "                cuisines,\n",
    "                cost_for_2, \n",
    "                featured_in]\n",
    "            \n",
    "        except: \n",
    "            pass\n",
    "    \n",
    "    \n",
    "    try: # go to next page\n",
    "        next_page = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, '#search-results-container > div.search-pagination-top.clearfix.mtop > div.row > div.col-l-12 > div > div > a.paginator_item.next.item')))\n",
    "        next_page.click()\n",
    "    except: \n",
    "        print(' Final page reached')\n",
    "        break \n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occasion</th>\n",
       "      <th>name</th>\n",
       "      <th>avg review</th>\n",
       "      <th>review count</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>address</th>\n",
       "      <th>cuisines</th>\n",
       "      <th>cost for 2</th>\n",
       "      <th>featured in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>Pizzeria Libretto</td>\n",
       "      <td>4.5</td>\n",
       "      <td>(1,010 Reviews)</td>\n",
       "      <td>Ossington Avenue, Trinity Bellwoods</td>\n",
       "      <td>221 Ossington Avenue, Toronto M6J 2Z8</td>\n",
       "      <td>[Pizza, Italian]</td>\n",
       "      <td>CA$50</td>\n",
       "      <td>[Hipster Hangouts]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>KINKA IZAKAYA</td>\n",
       "      <td>4.6</td>\n",
       "      <td>(1,166 Reviews)</td>\n",
       "      <td>Church Street, Church And Wellesley</td>\n",
       "      <td>398 Church Street, Toronto M5B 2A2 2A2</td>\n",
       "      <td>[Japanese, Asian]</td>\n",
       "      <td>CA$55</td>\n",
       "      <td>[Unique Dining]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>Pai</td>\n",
       "      <td>4.9</td>\n",
       "      <td>(614 Reviews)</td>\n",
       "      <td>Duncan Street, Entertainment District</td>\n",
       "      <td>18 Duncan Street, Toronto</td>\n",
       "      <td>[Thai, Asian]</td>\n",
       "      <td>CA$50</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>QUICK BITES</td>\n",
       "      <td>Banh Mi Boys</td>\n",
       "      <td>4.7</td>\n",
       "      <td>(941 Reviews)</td>\n",
       "      <td>Queen Street West, Fashion District</td>\n",
       "      <td>392 Queen Street West, Toronto</td>\n",
       "      <td>[Sandwich]</td>\n",
       "      <td>CA$25</td>\n",
       "      <td>[Pocket Friendly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>QUICK BITES</td>\n",
       "      <td>The Stockyards</td>\n",
       "      <td>4.6</td>\n",
       "      <td>(734 Reviews)</td>\n",
       "      <td>Saint Clair Avenue West, Forest Hill</td>\n",
       "      <td>699 St Clair Avenue West, Toronto M6C 1B2</td>\n",
       "      <td>[BBQ, Burger]</td>\n",
       "      <td>CA$25</td>\n",
       "      <td>[Kickass Burgers, Barbecue &amp; Grill, Grill My C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        occasion               name avg review     review count  \\\n",
       "0  CASUAL DINING  Pizzeria Libretto        4.5  (1,010 Reviews)   \n",
       "1  CASUAL DINING      KINKA IZAKAYA        4.6  (1,166 Reviews)   \n",
       "2  CASUAL DINING                Pai        4.9    (614 Reviews)   \n",
       "3    QUICK BITES       Banh Mi Boys        4.7    (941 Reviews)   \n",
       "4    QUICK BITES     The Stockyards        4.6    (734 Reviews)   \n",
       "\n",
       "                            neighborhood  \\\n",
       "0    Ossington Avenue, Trinity Bellwoods   \n",
       "1    Church Street, Church And Wellesley   \n",
       "2  Duncan Street, Entertainment District   \n",
       "3    Queen Street West, Fashion District   \n",
       "4   Saint Clair Avenue West, Forest Hill   \n",
       "\n",
       "                                     address           cuisines cost for 2  \\\n",
       "0      221 Ossington Avenue, Toronto M6J 2Z8   [Pizza, Italian]      CA$50   \n",
       "1     398 Church Street, Toronto M5B 2A2 2A2  [Japanese, Asian]      CA$55   \n",
       "2                  18 Duncan Street, Toronto      [Thai, Asian]      CA$50   \n",
       "3             392 Queen Street West, Toronto         [Sandwich]      CA$25   \n",
       "4  699 St Clair Avenue West, Toronto M6C 1B2      [BBQ, Burger]      CA$25   \n",
       "\n",
       "                                         featured in  \n",
       "0                                 [Hipster Hangouts]  \n",
       "1                                    [Unique Dining]  \n",
       "2                                                 []  \n",
       "3                                  [Pocket Friendly]  \n",
       "4  [Kickass Burgers, Barbecue & Grill, Grill My C...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "occasion        object\n",
       "name            object\n",
       "avg review      object\n",
       "review count    object\n",
       "neighborhood    object\n",
       "address         object\n",
       "cuisines        object\n",
       "cost for 2      object\n",
       "featured in     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants.to_csv('raw_restaurants_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
